

\documentclass[11pt,a4paper]{article} 
\setcounter{secnumdepth}{3}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{pdflscape}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage[margin=1.5in]{geometry}
\usepackage{caption}
\usepackage[font=footnotesize]{caption}
\usepackage{apacite}
\usepackage{color}
\usepackage{amsmath}
\usepackage{booktabs} 
\usepackage{xcolor}
\usepackage{float}
\usepackage{array}
\usepackage{setspace}
\usepackage{gensymb}
	\doublespacing
	
	
\definecolor{green}{rgb}{0,1,0}
\newcommand{\NS}[1] {{\textcolor{green}{#1}}}
\newcommand{\TM}[1] {{\textcolor{orange}{#1}}}
\newcommand{\AT}[1] {{\textcolor{blue}{#1}}}

	\begin{document}
	
	
%\section{Issues}
%
%
%\begin{itemize}
%
%\item addm is already using relative value signals - our approach takes context dependence into account twice?
%\item probability approach: how to properly explain the axis rotation
%\item probability approach: is the non-symmetric triangle an issue?
%\end{itemize}

\newpage

\section{Comments}

 Suggestions from Neil

We have two big technical innovations in the model fitting that you need to highlight as strengths of the work:

1. Highlight how innovative the "novel probability distribution" approach is. Cite the Diedereich and related papers we looked at about a year ago.

1.5. Also highlight that we are using the eye movements on a single trial to predict choice and choice time on that very same trial. This is a nontrivial innovation.


2. Add some sentence to make it more clear that it really is random in terms of movies assigned to triplets!

3. Amplify discussion on p. 20 with an example to make it really clear why simulations are particularly influenced by the rare events. 



"derive the the choice" -> say "exact choice probability without the stochasticity due to simulation"

I think the explanation of the diffusion of density in Figure 8 needs a little more. We need to say that the density entering one of the edge regions at a given time step is the likelihood of choosing that option at that time step.

I didn't understand the point of the estimation on p. 29. 

\newpage

\section{Introduction} \label{chap1intro}



While there is ample evidence that our decisions are profoundly affected by the decision context, how exactly the perceived subjective value of an option changes as a function of choice environment is still a matter of debate within the literature. 

Over the past decades, several theoretical models of context-dependent valuation have been proposed. One of the earliest of these is Parducci's range-freguency theory (RFT; \citeNP{Parducci1963}, \citeyearNP{Parducci1965}), a highly influential theory in psychophysics, which offers an account of how objective stimuli get translated into subjective quantities. According to RFT, the perceived magnitude of the stimulus depends on two components, its range and rank value within the stimuli set. The range value of the stimulus reflects its position with respect to the highest and lowest stimuli in the set, whereas the rank value reflects its position within the ordered set of stimuli. RFT has proven to be an excellent explanatory framework for contexts effects observed in a range of domains, such as strategic decision making \cite{Vlaev2006a}, price judgments \cite{Niedrich2009}, and even pain perception \cite{Watkinson2013}.  


The range and rank principles have also been influential outside the RFT framework. For example, the effects of stimulus range on discrimination performance and magnitude judgments have long been the focus of perceptual psychology \cite{Lockhead1986}. More recently, range effects have been increasingly incorporated into models emerging from the interdisciplinary field of decision neuroscience. These models mostly focus on explaining patterns of neural activity during decision-making tasks in fMRI experiments. Given that neural firing rates are bounded from above due to biophysical constraints, it is a natural assumption that some sort of adaptive mechanism must take place to accommodate differences in the range of stimulus values that can be experienced in the real-world (e.g., \citeNP{Padoa-Schioppa2009}; \citeNP{Soltani2012}; \citeNP{Rangel2012}; \citeNP{Louie2013}).

%Value normalization in decision making: theory and evidence

The rank principle has also been successfully applied in a range of choice domains. For example, in an fMRI experiment where participants were shown pictures of monetary amounts they could win, \citeA{Mullett2013} have found that activity in certain brain regions reflected the current stimulus' rank position within the entire set of stimuli. In a socioeconomic context, several studies have shown that the rank position of one's income within their respective social reference group (e.g., workplace, neighbourhood), but not the absolute level of income, is a significant predictor of a series of health outcomes including mental health, self-reported happiness, and job satisfaction (e.g., \citeNP{Clark2008}; \citeNP{Brown2008a}; \citeNP{Boyce2010}; \citeNP{Daly2015}).

The range and rank principles are two distinct approaches to value normalisation, where the transformed values are required to fall between 0 and 1. These can be contrasted with simpler forms of normalisation, where the values are divided by the maximum value in the set, which serves as a natural reference point for a subjective valuation scale. In the context of a choice experiment, this maximum can be represented by the highest value in the current choice trial (the local maximum), or, equally, it can be the highest value experienced during the entire experiment (the global maximum), which is equivalent to simply normalising all values by a constant.

In this research project, our primary aim was to contrast these four different forms of context dependence (range, rank, local and global maximum normalisation) on the basis of their explanatory power. Our empirical strategy was to present participants with choice triplets in two experiments, in the form of complex preferential stimuli in Experiment 1, and perceptual stimuli in Experiment 2. More importantly, the ``objective value''  of each of the three options in each trial could be quantified in both experiments, which allowed us to investigate how these four value transformation rules fare in predicting choice behaviour.

There exists a wide range of choice models in cognitive psychology, many of which could serve as equally suitable theoretical frameworks to investigate context-dependence in value-based choice. In this research project, we chose to employ the theoretical framework of a hugely influential cognitive model of choice, the drift diffusion model (DDM; \citeNP{Ratcliff1978b}) and one of its popular extensions, the attentional drift diffusion model (aDDM; \citeNP{Krajbich2010}; \citeNP{Krajbich2011}), which incorporates the role of eye-movements within the standard DDM. 

Using data from Experiment 1, we contrasted the four value transformation rules by fitting the aDDM with each transformation rule variant to the choice and reaction time data and compared the resulting likelihoods. Following this quantitative test, we also conducted a qualitative comparison of the four rules, by contrasting choice proportions from both experiments with our predictions from simulating out the DDM with each rule variant. The next section gives a brief overview of the DDM and its extension, the aDDM.



\subsection{The drift diffusion model} \label{chap1addmexplain}


How do people choose when facing multiple options? What happens exactly during the choice process, what is the cognitive mechanism underlying the comparison of the alternatives? These are the questions process models of choice seek to answer. In cognitive psychology, one particularly influential type of process models is the family of sequential sampling models. 

The overarching idea behind these models is that the evolution of preference in a given choice process is the result of noisy accumulation of evidence for each alternative throughout the decision process (hence the name “sequential sampling”), and a response is made when the accumulated evidence exceeds a certain threshold. Within the broader family of sequential sampling models, there is a wide variety of models depending on whether the evidence is accumulated separately and independently for each option and whether the threshold is defined to be absolute or relative (\citeNP{Teodorescu2013}; \citeNP{Forstmann2016}).

Of particular interest in psychology and cognitive neuroscience is a sequential sampling model that assumes a relative decision rule, and a separate and independent accumulation process for each choice option under consideration. In discrete time, this is modelled as a random walk process, whereas in continuous time it can be characterised by a diffusion process. The latter form is called the DDM (e.g., \citeNP{Ratcliff1998a}; \citeNP{Ratcliff2008}), which is now the workhorse sequential sampling model in cognitive psychology. 

In the drift diffusion framework, a key parameter of the model is the drift rate, which determines the average rate at which one of the thresholds are being approached during the choice process \cite{Voss2004a}. It also reflects the degree of similarity between the two options, and thus can be seen as a measure of task difficulty: when the options are very similar and the task is difficult, the process will have a low drift rate, and therefore it will take longer to reach one of the thresholds. Conversely, when the options are easily discriminable and the choice is ``easy'', the drift rate will be high, and a threshold is reached faster. Figure \ref{fig:randomwalk} illustrates one such evidence accumulation process in the drift diffusion framework.

\begin{figure}[h]
\centering
\caption{Illustration of the evidence accumulation process with options A and
B.}
\includegraphics[width=0.9\textwidth]{c1_randomwalk.pdf}
\label{fig:randomwalk}
\end{figure}


While the DDM in psychology was first used as a model of memory retrieval \cite{Ratcliff1978b}, it has since been applied to a wide range of choice task domains, including lexical decision making \cite{Ratcliff2004}, numerosity discrimination \cite{Leite2011} and emotional processing \cite{Mueller2016}. The popularity of the DDM in these various research areas stems from a number of factors. 

First, and most importantly, the DDM both predicts reaction time distributions and choice probabilities remarkably well (\citeNP{Ratcliff1999}; \citeNP{Forstmann2016}). Second, it has been shown that manipulations of the decision task (such as changing task difficulty, accuracy motivation and reward structure of the task) correspond to expected changes in model parameters (drift rate, threshold distance and the starting point of the accumulation process respectively), indicating that the model is successful in capturing the cognitive mechanism underlying choice processes \cite{Voss2004a}. Lastly, the model is inherently intuitive: it provides an elegant and plausible description of the evolution of preferences during the deliberation phase of decision making.

In addition to providing a psychologically plausible model of choice behaviour, the drift diffusion model has also been successfully applied in the field of cognitive neuroscience to explain both high- and low-level cognitive processes \cite{Forstmann2016}. Studies measuring decision-related neural activity in monkeys have found that over the course of a motion discrimination task, the firing rates of neurons in the lateral intraparetial cortex (LIP; an area in the brain responsible for attentional and decision-related processes, e.g. \citeNP{Shadlen2008}) exhibit a pattern which closely resembles to the accumulation of noisy evidence (e.g. \citeNP{Churchland2011}). In humans, studies using functional magnetic resonance imaging (fMRI) have identified distinct areas of the brain whose activation changes following value manipulations of model parameters (through changing the task design) in the DDM (for a review see \citeNP{Mulder2014}). 

Owing to the popularity of the DDM, several extensions of the model have been proposed. One notable example is the incorporation of attentional processes in binary and trinary value-based decisions, known as the aDDM (\citeNP{Krajbich2010}; \citeNP{Krajbich2011}). Compared to the DDM, the aDDM modifies the drift rate for the accumulation process based on the pattern of visual fixation during choice, resulting in a faster accumulation process for the option that is being fixated at a given time point. The mathematical formulation of the accumulation process in the trinary case with options left, center and right, when option left is fixated is as follows:

\begin{equation} \label{Evidence1}
E_{t}^{left}=E_{t-1}^{left}+d\cdot r^{left}+\varepsilon_{t}^{left}
\end{equation}

\begin{equation} \label{Evidence2}
E_{t}^{center}=E_{t-1}^{center}+\theta\cdot d\cdot r^{center}+\varepsilon_{t}^{center}
\end{equation}


\begin{equation} \label{Evidence3}
E_{t}^{right}=E_{t-1}^{right}+\theta\cdot d\cdot r^{right}+\varepsilon_{t}^{right},
\end{equation}

where $E_{t}$ is the amount of evidence accumulated for a given option
(the value of the accumulator corresponding to an alternative) up
until time period $t$, $\theta$ is the penalty on the unattended
items that can vary between 0 and 1 ($\theta=1$ corresponding to the standard DDM model with no role of visual fixations, and $\theta=0$ corresponding to the case of maximum penalty, such that the accumulation process is maximally dependent on the visual fixations), $d$ is a constant that governs the rate of accumulation,
$r$ is the subjective value of the given option, and $\varepsilon$ is the noise
in the accumulation process. Therefore, for a given option, the total
amount of accumulated evidence in each time period is given by the
sum of the value of that accumulator in the previous time period,
the value of the option discounted by the penalty on the unattended
item (if it is not currently attended), and the noise component $\varepsilon\sim N(0,\sigma^{2})$ (see Equations \ref{Evidence1}-\ref{Evidence3}). The relative evidence accumulated for each option is then defined as follows:

\begin{equation} \label{REA1}
V_{t}^{left}=E_{t}^{left}-max(E_{t}^{center},E_{t}^{right})
\end{equation}

\begin{equation} \label{REA2}
V_{t}^{center}=E_{t}^{center}-max(E_{t}^{left},E_{t}^{right})
\end{equation}


\begin{equation} \label{REA3}
V_{t}^{right}=E_{t}^{right}-max(E_{t}^{left},E_{t}^{center})
\end{equation}

As can be seen form Equations \ref{REA1}-\ref{REA3}, the aDDM implements a next to best decision rule: at any given time step, each item's accumulator competes with the higher out of the other two. A choice is made when one of the relative evidence accumulators reaches a given threshold. The free parameters in the aDDM are $\theta$, \textit{d} and $\sigma^{2}$. Figure \ref{fig:driftrates} illustrates an accumulation process in the aDDM framework. In general, through $\theta$, the relative decision value for the fixated item increases, while it decreases for the unfixated items. Increasing $d$, the speed of integration results in a faster accumulation process for all options, reducing reaction times. Increasing $\sigma^{2}$ results in a much less deterministic accumulation process. The speed of the accumulation also depends on the value of the options, $r$. 

\begin{figure}
\captionsetup{justification=centering}
\caption{Illustration of the evidence accumulation process in the aDDM framework
($\mathit{\mathit{r^{left}=4, r^{center}=3, r^{right}=6, d=0.0002}, \theta=0.3, \sigma^{2}=0.001}$)}
\includegraphics[width=1\textwidth]{c1_driftrates.pdf}
\label{fig:driftrates}
\end{figure}

 Several studies have demonstrated the strong link between eye movements and subsequent choice behaviour. In a preferential choice experiment with pairs of faces used as stimuli, \citeA{Shimojo2003} have found that participants were more likely to fixate on the item they ended up choosing, a phenomenon called the gaze bias, which has also been observed in other eye tracking experiments involving preferential choice tasks (e.g. \citeNP{Armel2008}; \citeNP{Bird2012}). This effect tends to be especially pronounced towards the end of the decision: when retrospectively plotting how attention changes seconds before the choice was made, there is a much higher likelihood of the finally fixated item being the finally chosen one too (compared to the beginning of the trial). This is called the gaze cascade effect (e.g. \citeNP{Shimojo2003}; \citeNP{Glaholt2009}) or the late onset bias \cite{Mullett2016}. \citeA{Shimojo2003} argued that this effect is a result of a feedback loop between preference and visual orienting behaviour. 

While these patterns provide indisputable evidence for the intimate link between attention and choice behaviour, the assumption that eye movements have a casual effect on preference formation has proven difficult to demonstrate. This difficulty stems from the fact that designing an eye-tracking experiment that mimics real-life choice scenarios, whilst exogenously manipulating gaze in a non-invasive fashion is extremely challenging from a methodological point of view. Attempts to overcome this difficulty through exogenous gaze manipulations included explicitly controlling exposure time by displaying only one item at a time \cite{Armel2008}, instructing participants to fixate on the item indicated with a specifically coloured frame in a binary choice task \cite{Lim2011}, and prompting a decision once the target has been fixated for a pre-determined amount of time \cite{Parnamets2015}. While these studies have demonstrated that items that were fixated longer were also more likely to be chosen, the artificial nature of these choice scenarios mean that they do not provide unequivocal evidence that eye movements have a causal effect on preferences in real-life choice scenarios. 

However, in a recent study, \citeA{Gwinn2019} directly tested the causal effect of eye movements on preferences. They used probability cueing, an elegant, non-invasive attentional learning technique, which induces attentional biases that spill over to a subsequent choice task. Across four studies, their results lend support to a causal relationship between attention and choice, providing the strongest evidence for this mechanism yet.

While the causal role of fixations in choice behaviour is not a critical assumption in the aDDM framework \cite{Krajbich2019}, the model can accommodate both the gaze bias and gaze cascade effect. First, fixating on one item for longer means that the amount of relative evidence accumulated in favour of this item will be higher, therefore it is more likely to be finally chosen (gaze bias effect). Second, because evidence accumulation is faster when an item is being fixated, it is more likely that the item's relative evidence accumulator reaches the threshold during a fixation on that item (gaze cascade effect). A comprehensive investigation of six eye-tracking studies have found that attention amplifies the underlying value of the option under consideration, as opposed to providing a value-independent boost in form of a constant, supporting the multiplicative formulation of the aDDM \cite{Smith2019}. In addition, comparisons of aDDM predictions and actual eye-tracking data have shown that the aDDM provides a remarkably good fit to the fixation, reaction time and choice data (\citeNP{Krajbich2010}; \citeNP{Krajbich2011}). Owing to its high explanatory power, we decided to investigate context-dependency within the aDDM framework. 

When fitting the aDDM to actual choice data, the value of the options (and consequently the drift rate) is usually defined as the item ratings given by participants in a ratings task that precedes the choice task ($r^{left}$, $r^{middle}$, and $r^{right}$ in Equations \ref{Evidence1}-\ref{Evidence3}). These ratings are assumed to reflect the “objective value” of an option, evaluated independently from the other options available. In this research project, we aim to incorporate the idea of context-dependency within the aDDM framework through the item ratings. In particular, we applied the four value transformation rules (range, rank, local, global maximum) to the preference ratings to accommodate and compare these rules within the aDDM framework.


These modifications reflect changes in how the collected evidence samples are defined within the model framework. In the original model it is the absolute value of the options (preference ratings on a scale from -10 to 10; e.g., \citeNP{Krajbich2011}) that governs the drift rate, whereas in our formulation, it is the normalised, subjective values of the options that feeds into the accumulation equation at each time step. Importantly, we did not explicitly modify how the options are contrasted and integrated within the model (described in Equations \ref{REA1}-\ref{REA3}).



\section{Overview of Experiment 1 and 2}

In the following two experiments, our goal was to capture the idea of context sensitivity within the aDDM framework. Experiment 1 was a preferential choice experiment, where participants were presented with choice triplets created from a 100 movie posters, while their eye movements were recorded. In a separate rating stage that preceded the choice task, we obtained independent preference ratings from each participant on our set of 100 movies. Using these ratings as inputs to the four value transformation rules, we investigated how the choice context affects the preferences over the options. In Experiment 2, we were interested in the same question, but we used perceptual stimuli, in the form of rapidly updating sequences of numbers drawn from a normal distribution with a fixed mean (taken from \citeNP{Tsetsos2012a}). Analogously, we used these fixed means as inputs to the value transformation rules.


For a thorough investigation of the explanatory power of the four value transformation rules, we used two fundamentally different approaches, a quantitative and qualitative approach. First, using data on eye movements during choice from Experiment 1, we obtained the best fitting set of aDDM model parameters for each valuation rule and participant, and compared the resulting likelihoods across the four value transformation rules. In order to obtain these best fitting parameters, we used two alternative methods to estimate the choice probabilities: a traditional simulations-based method, and a novel probability distribution method, which circumvents the problem arising from simulating out a stochastic model. Second, using a DDM simulations approach, we compared the choice proportion predictions for each value transformation rule with the results from Experiment 1 and 2, which served as a further qualitative test of the explanatory performance of each rule. 

Results from the model fitting approach suggest that subjective valuation mostly depends on the absolute value of the choice options, and, albeit to a lesser extent, also reflects  relative value sensitivity, a finding which was supported by the results from the qualitative comparison as well. We discuss these results in light of findings from neuroeconomic studies investigating the neural correlates of value-based choice.

\section{Subjective Transformation Rules} \label{chap1subjtrexplained}

We considered the four value transformation rules detailed in section \ref{chap1intro}: the range, rank, local, and global maximum rule. Each rule takes in three “objective values” $x_1, x_2, x_3$  (these are the “raw” independent preference ratings for each movie in Experiment 1, and the mean of each distribution from which the rapidly updating sequence of numbers are drawn in Experiment 2), and transforms these into normalised “subjective values” (required to fall between 0 and 1). 

 \textbf{Range Rule.} The range value reflects the stimulus' perceived distance from the stimulus with the lowest value as a proportion of the overall distance between the highest and lowest valued stimulus in the stimuli set. It captures the idea that valuation is sensitive to the highest and lowest value encountered (or, equivalently, to the overall range of values) in a given choice set. Formally, this can be described by the following equation:
 
\begin{equation}
Range_{i}=\frac{x_i - min(x_1,x_2,x_3)}{max(x_1,x_2,x_3)-min(x_1,x_2,x_3)}
\label{eq:range}
\end{equation}
 Note that the items with the lowest and highest original values are always assigned 0 and 1 respectively, while the middle item's value can vary between 0 and 1.
 
 
 \textbf{Rank Rule.} The rank rule also follows from RFT, and reflects the “frequency” of the stimuli, which can be translated as its ranked ordinal position in the choice set. The rank rule reflects a somewhat simpler mechanism of valuation, whereby the subjective value of an item is solely determined by the number of items with lower or higher values in the choice set, and the extent of the difference between item values does not matter. Formally, given an ordered set of three stimuli $x_1, x_2, x_3$ , the rank value of a stimuli is given by
 
\begin{equation}
Rank_{i}=\frac{i-1}{n-1}
\label{eq:rank}
\end{equation}

Note that according to the rank rule, the three subjective values assigned to the items with the lowest, middle and highest value are always 0, 0.5 and 1, respectively.

\textbf{Local Maximum Rule.} The local maximum rule generates subjective value representations by dividing each stimuli's value by the highest value encountered on that trial, and in this way it corresponds to the normalised version of the raw ratings used in \citeA{Krajbich2011}. This reflects a bias towards the most rewarding, and hence potentially most salient option at the time of the choice. Formally, the subjective value of a stimuli according to the local maximum rule is given by

\begin{equation}
Local max_{i}=\frac{x_i}{max(x_1,x_2,x_3)}
\label{eq:locmax}
\end{equation}

Note that the stimuli with the highest value is always assigned a subjective value of 1, while the other two values can vary between 0 and 1 (exclusive).

\textbf{Global Maximum Rule.} The global maximum rule is identical to the Local Maximum Rule, except that the objective values are normalised using the highest value encountered in the whole of the experiment (and not just on that trial). This means that all values are normalised by the same constant, therefore, the global maximum rule is equivalent to the original version of the aDDM (e.g., \citeNP{Krajbich2011}), and can serve as a natural reference point to test whether the explanatory power of the model can be increased with a different value transformation rule. Formally, in an experiment where the items that can be encountered are $x_1, x_2, ..., x_n$, the subjective value of a stimuli set according to the global maximum rule is given by

\begin{equation}
Globalmax_{i}=\frac{x_i}{max(x_1,x_2,...,x_n)}
\label{eq:globmax}
\end{equation}

Note that when an item in the current trial has the highest value in the whole of the experiment, this rule is equivalent to the local maximum rule, otherwise the values can vary between 0 and 1 (exclusive). 

\section{Choice Set Manipulations} \label{chap1choicesetman}

After identifying the four value transformation rules, the next step was to find a set of choice set manipulations for which these transformation rules (accommodated within an aDDM or DDM framework) derive different predictions about choice behaviour. These choice manipulations represent some modification of the three options' objective values based on a certain rule (e.g. doubling each value, or adding a constant to each of them). The key idea is that the four value transformation rules differ in their predictions about how these choice set manipulations affect choice proportions, which allowed us to assess the empirical performance of each subjective transformation rule. 

Based on a series a simulations, we chose to investigate the effect of the following four distinct choice set manipulations: adding the same constant to each of the three values, multiplying each value by a constant, and having a distant or a close second, and third value. Figure \ref{fig:choicesetmanip} shows the subjective values (these are required to fall between 0 and 1) derived from each transformation, assuming a value scale from 1 to 7. The orange dots are the original values, while the purple dots show the values after the transformation (for example, in the case of adding a constant, the original value set is 1,2,4, while the transformed values are 4,5,7).

\begin{figure}
\captionsetup{justification=centering}
\centering
\caption{Subjective values by choice set manipulation and value transformation rule. The four columns show each choice set manipulation, while the rows correspond to the four value transformation rules.}
\includegraphics[width=1\textwidth]{explain.pdf}
\label{fig:choicesetmanip}
\end{figure}

Our original plan was to present participants with these seven distinct trinary choice sets (124, 457, 123, 246, 137, 167, 567) to maximise the discriminatory power of our experiments. However, due to an experimenter error, in Experiment 1, the displayed choice options were quasi-random, resulting in 84 unique choice sets instead of the originally planned seven. We nevertheless proceeded with fitting the aDDM to the data from Experiment 1, and had enough data for the relevant seven choice sets to conduct a qualitative comparison of choice behaviour in Experiment 1 and 2.


\section{Experiment 1}

\subsection{Method} \label{chap1exp1method}

Experiment 1 was a preferential choice experiment, where participant's eye movements were recorded during choice. Based on previous eye-tracking studies (e.g., \citeNP{Krajbich2010}; \citeNP{Krajbich2011}), we decided in advance that a sample of 50 participants should provide enough statistical power for our purposes. To reach this sample size, we recruited sixty participants overall, out of which ten participants could not be eye-tracked. Participants were recruited through the University of Warwick's Research Participation System, and were paid £7.00 for taking part in the experiment. We did not record data on participants' gender, as we did not expect it to affect the results. Ethical approval was obtained from the Department of Psychology, University of Warwick.

The experiment consisted of two parts. First, participants who signed up for the study were required to complete an online questionnaire, where they had to rate 110 movies on a scale from 1 to 7, based on how much they liked the given movie (1 being not at all and 7 being very much so). We also asked them whether they have seen the movies before. The rating task began with 10 test trials (these were the same movies for all participants), so that participants could familiarise themselves with the task and the range of movies they will be required to rate. Then, they were informed that the actual rating task is about to start. During this task, participants were presented with the 100 movies in a randomised order, and we instructed them to try to use the whole range of the scale as much as possible. This was important, because the second part of the experiment relied on these ratings, and could not be run without at least one movie for each rating. Some participants failed to do this, and so they were asked again to complete this task before coming to the lab for the second part of the experiment. Figure \ref{fig:ratingstask} shows an example trial from this task, which took about 15 minutes on average. 

\begin{figure}[htb!]
\captionsetup{justification=centering}
\centering
\caption{Example rating task from the first part of Experiment 1. }
\includegraphics[width=0.58\textwidth]{ratingstask.png}
\label{fig:ratingstask}
\end{figure}


Those who successfully completed the first part were invited to the lab for the second part of the study. In the second part, participants were presented with 100 trinary sets of the pre-rated movies, and were asked to pick the one they liked the most on each trial by pressing the corresponding keyboard key (left, down, right arrow), while their eye movements were recorded at 500 Hz using an EyeLink 1000 (SR Research). The order of the choice triplets and the display order of the three movies in a given trial were both randomised. The eye tracker was calibrated after every 25 choices (four times overall over the course of the experiment), and each trial began only after participants fixated on a centrally presented fixation cross for 500 ms. Figure \ref{fig:exp1_movieschoice} shows an example trial from the second part of this experiment.

\begin{figure}[htb!]
\captionsetup{justification=centering}
\centering
\caption{Example choice task from the second part of Experiment 1. }
\includegraphics[width=0.7\textwidth]{exp1_movieschoice.jpg}
\label{fig:exp1_movieschoice}
\end{figure}



\subsection{Stimuli}

We chose 110 movies that received the most votes in 10 distinct genres (adventure, comedy, drama, family, fantasy, history, mystery, romance, sci-fi, thriller) on IMDb as of March, 2016. In the first part of the experiment, the first ten trials were practice trials (one movie from each genre), which aimed to give participants an idea about the range and type of movies they will be asked to rate. 

In the second part of the study, the displayed trinary sets were originally generated based on the participant's ratings to reflect the choice set manipulations. However, as mentioned above, the choice sets displayed during the experiment were unintentionally quasi-random, due to the incorrect numbering of the 110 stimuli pictures. However, each number still corresponded to a unique movie. This resulted in 84 unique trinary choice sets (defined by the raw rating of each of the three options), as opposed to the originally planned seven, described in section \ref{chap1choicesetman}. 

In order to avoid the same set of movies appearing again, the script that generated the choice triplets was written to ensure that all the stimuli with a given rating gets used before any repetition of stimuli occurs. While we tried to vary the stimuli appearing as much as we could, repetition was inevitable in some cases, since some of the participants gave very uneven ratings (e.g., gave a rating of 1 to only a few movies). 

Given that our main aim was to fit the aDDM to the data to compare each value transformation variant, we decided it was still worth proceeding with the analysis with the current dataset (even though the data now contained considerably fewer trials that could help us delineate the differences in the explanatory power of the four value transformation rules). 

\subsection{Exclusion criteria}

As mentioned in section  \ref{chap1exp1method}, we had usable eye-tracking data from 50 participants. For a few participants, the calibration quality was not satisfactory in some parts of the experiment, and therefore we excluded these trials (accounting for about 2.5\% of all fixations). We also excluded the first three trials of each participant, and each trial right after a calibration, to make sure we only include fixations that are part of the choice process. We then excluded fixations that fell outside the three areas of interest, and trials in the upper 1\% of the reaction time distribution. Finally, we only kept trials where all three of the choice items were fixated at least once. 


\section{Fitting the aDDM}

\AT{Is this understandable?}
Using data from Experiment 1, we wished to compare the four value transformation rules within the aDDM framework, on the basis of their respective likelihoods. When fitting the aDDM, the common approach (e.g., \citeNP{Krajbich2010}; \citeNP{Krajbich2011}; \citeNP{Fisher2017}) is to fit the model on the group-level, and simulate out all parameter ($\theta$, the penalty on the unattended item, $\sigma$, the noise parameter, and $d$, the speed of integration) and preference rating combinations with fixations sampled from the empirical distribution of fixations, conditional on the preference rating difference. 

Then, given a discrete number of reaction time bins, the number of simulations falling into each choice and reaction time bin can be calculated for all parameter combinations and rating difference, and the probability that a simulation trial finishes in a given choice and reaction time bin can be derived. To obtain the log-likelihood of the data for each parameter combination, these probabilities are multiplied by the number of empirical data points falling into the same choice and reaction time bin, and their logarithm is taken and summed up. One or two iterative grid searches can be carried out using this estimation method, resulting in the final estimate of best fitting parameters, and the corresponding log-likelihood.


\AT{Fisher says: "The model requires a large amount of data to estimate the parameters accurately, and fitting them at the individual level would result in highly noisy estimates." Any thoughts on this?}

Our empirical approach differs from this method in several respects. First, in contrast with their group-level approach, we derived the best fitting parameters for each subject. Therefore, our primary aim was to find the best fitting parameter set and the corresponding likelihood value for each participant and transformation rule (of which there were 200, given 50 participants and four subjective value transformation rules) to determine which transformation rule yields the best fit for each participant. Second, we derived the predicted probability of each trial falling into a given choice and reaction time bin, using the eye movement pattern on that very trial (as opposed to probabilistically sampling it from an empirical distribution conditional on the rating difference). Finally, to evaluate the robustness of our estimates as well as to circumvent a methodological issue stemming from applying a traditional simulations-based approach to a stochastic model, we also used a novel probability distribution-based approach to derive the best fitting parameter combinations and corresponding log-likelihoods for each value transformation rule.

Before the parameter estimation, we discretized the eye movement data. More specifically, we divided each trial into 200 ms bins, where each bin was one step in the evidence accumulation process assumed by aDDM. The fixated item in a bin was sampled probabilistically, based on the proportion of time spent on fixating on a given item in each bin. For example, if in one bin, 50 ms was spent on fixating on item 1, and 150 ms was spent on fixating on item 2, then in the simulations item 1 had a 25\% while item 2 had a 75\% probability of being chosen as the fixated item in that bin. 

When fitting the aDDM for each value transformation rule, we used the transformed ratings in place of $r$ described in Equations \ref{Evidence1}-\ref{Evidence3} in section \ref{chap1addmexplain}. However, the unintentionally wide variety of value triplets displayed in Experiment 1 posed a question about how to derive the range transformed values in case there were two or three identical values in the choice set (it is straightforward in the case of the two maximum rules and the rank rule). We decided to code the transformed range values as 1 if all values were identical. If there were two equal values in a triplet, they were either coded as 1 or 0 (depending on whether the third value was lower or higher than the two identical ones, respectively). 


\subsection{Simulations method}

To obtain the best fitting parameters for each value transformation rule, we first used a traditional simulations-based method. Specifically, we simulated out each trial 100,000 times, and calculated the probability that the eventually chosen item was selected in the correct time bin. Note that there are two sources of variation in these simulations: the inherent noise in the accumulation process (captured by $\sigma$), and the non-deterministic fixation pattern arising from the transformation of the fixation data into time bins.

To find the best fitting parameter sets, we started off with a grid search with the following values: $\theta=\{0.2, 0.45, 0.6, 0.85, 1\}$, $\sigma=\{0.1, 0.14, 0.2, 0.28, 0.4\}$, $\textit{d}=\{0.1, 0.17, 0.31, 0.56, 1\}$, 125 parameter sets overall, for each participant and value transformation rule. These values were chosen to make sure that most participants' best fitting values (from the values in the grid) fell in the middle of the value range. This was done to ensure that in the subsequent optimization process, the algorithm does not have to move considerable lengths in the parameter space to find the best fitting parameter set.

Upon obtaining the best fitting parameter set from the grid, we started a Nelder-Mead optimization algorithm, using the resulting parameter set from the grid search as starting points for each participant and value transformation rule. This was repeated once more using the results from the first Nelder-Mead optimization process as a starting point, to increase the probability that we find the parameter set that produces the highest likelihood of producing the data. For the overwhelming majority of participants and transformation rules, running the second Nelder-Mead did not improve the likelihood substantially.

We initially used 100,000 simulations to lessen the effect of noise (an inherent feature of the aDDM) and obtain reliable estimates (previous studies using simulations used between 1000 and 4000 simulations). However, an unanticipated effect of having such a high number of simulations was that trials that were not well predicted by the model ended up having a big effect on the Nelder-Mead process, indicating a non-smooth likelihood surface. 

For example, if there is just one trial for a participant that is very unlikely to occur with a given parameter set, whereas the rest of the trials are relatively likely to occur, then using such a high number of simulations can have a dramatic effect on the overall estimated likelihood for that participant and parameter combination, potentially changing it from minus infinity to a very high likelihood. Such significant jumps in the likelihood surface can easily lead to the Nelder-Mead process getting stuck at a given point. This is because the Nelder-Mead optimization method was initially developed for deterministic models, and it has been demonstrated that substantial noise in the underlying model can lead to false convergence (e.g., \citeNP{Chang2012}; \citeNP{BartonIvey1991}). To alleviate these concerns about the validity of the simulations method, we decided to compare the results from the simulations with those obtained from an alternative, deterministic implementation of the aDDM.


\subsection{Probability distribution method}

To circumvent the problem of the non-smooth likelihood surface, we utilised an alternative estimation method that is free of the inherent stochasticity within the aDDM framework. In a nutshell, our approach was to derive the probability distribution over the relative evidence states ($E_{1}-E_{2}$ and $E_{1}-E_{3}$ from Equations \ref{Evidence1}-\ref{Evidence3} in section \ref{chap1addmexplain}) for each time bin and parameter combination. This method allowed us to directly derive the exact choice probability for each trial in our data.

In order to restrict the finished relative evidence states (corresponding to combinations of $E_{1}$, $E_{2}$ and $E_{3}$ where the threshold had been reached, and one of the options had been chosen) to a bounded area within the relative evidence space, we chose to utilise a termination rule where the process is finished when the difference between the best option and the average of the other two reaches the threshold (see Figure \ref{fig:rulesfinished}), as opposed to the next best rule employed by \citeA{Krajbich2011}, which is also reflected in Equations \ref{REA1}-\ref{REA3} in section \ref{chap1addmexplain}. However, we did not expect this modification to have a substantial effect on our results, since previous research had shown that the two rules yield very similar predictions (see \citeNP{Krajbich2011}).

\begin{figure}
\captionsetup{justification=centering}
\centering
\caption{The finished evidence states with Next Best and Average of second and third termination rules.}
\includegraphics[width=1\textwidth]{rulesfinished.pdf}
\label{fig:rulesfinished}
\end{figure}

As mentioned, we wished to calculate the probability distribution over the relative evidence states $E_{1}-E_{2}$ and $E_{1}-E_{3}$ (each of which is represented by a dot on Figure \ref{fig:rulesfinished}) for a given parameter set and time step. Assuming that each step in the process can be described by a two-dimensional vector with components
\begin{equation}
\begin{array}{l}
\displaystyle x = E_{1}-E_{2} = d(\theta_{t}r^1-\theta_{t}r^2) + (\varepsilon_{t}^{1}-\varepsilon_{t}^{2})\\
\displaystyle y = E_{1}-E_{3} = d(\theta_{t}r^1-\theta_{t}r^3) + (\varepsilon_{t}^{1}-\varepsilon_{t}^{3}),\\
\end{array} 
\label{eq:axes1}
\end{equation}

the covariance matrix between the two axes is

\begin{equation}
\begin{array}{l}
COV = \begin{bmatrix}
       2\sigma^2 & \sigma^2 \\[0.3em]
       \sigma^2 & 2\sigma^2 \\[0.3em]
     \end{bmatrix}
\end{array} 
\label{eq:covariance}
\end{equation}

This covariance matrix is not diagonal, because the axes are correlated (due to the shared component $\varepsilon_{t}^{1}$ in the relative evidence states), which, when modelling the process, results in an ellipse whose axes are not parallel to the coordinate axes (see the left panel on Figure \ref{fig:rotate}). To simplify the subsequent calculations by eliminating the correlation between the axes, we can place them at a more convenient position, by rotating both axes by an angle $\alpha$ (as demonstrated in the right panel of Figure \ref{fig:rotate}). 
%This could be improved

\begin{figure}[htb!]
\captionsetup{justification=centering}
\centering
\caption{Demonstration of the correlation problem. The left panel shows the original axes, whereas the right panel shows the rotated axes with no correlation.}
\includegraphics[width=1\textwidth]{rotate.pdf}
\label{fig:rotate}
\end{figure}
 

Assuming $x'$ and $y'$ are the respective rotated versions of $x$ and $y$, they can be characterised as
\begin{equation}
\begin{array}{l}
\displaystyle x' = x cos(\alpha) + y sin(\alpha)\\
\displaystyle y' = -x sin(\alpha) + y cos(\alpha).\\
\end{array} 
\label{eq:axes2}
\end{equation}

The next step was to calculate the value of $\alpha$ that results in a diagonal covariance matrix between $x'$ and $y'$ (corresponding to no correlation between the two axes). One solution for this system is given by $cos(\alpha) = sin(\alpha)$, or $\alpha = 45\degree$. Expressed in terms of our original relative evidence states, a $45\degree$ degree anti-clockwise rotation results in the new axes defined as

\begin{equation}
\begin{array}{l}
\displaystyle x' = E_{1}-\frac{E_{2}+E_{3}}{2}\\
\displaystyle y' = \frac{E_{2}-E_{3}}{2}.\\
\end{array} 
\label{eq:axes1}
\end{equation}
 
As the right panel in Figure \ref{fig:rotate} demonstrates, this results in an ellipse whose axes are now parallel to the coordinate axes. In this transformed coordinate system, we can characterise the decision process as a multivariate normal distribution whose movement along the relative evidence bins is governed by the model parameters. To save computation time, the possible evidence states were approximated by bins (the x evidence space spanned from -2.5 to 1.5 with spacing 0.1 in 41 bins, whereas the y evidence space spanned from -1.5 to 1.5 with spacing 0.1 in 31 bins, resulting in $31x41 = 1271$ bins). Then, using the preference ratings $r$, the penalty on the unattended item $\theta$, the speed of integration $d$, and the variance of the normal distribution $\sigma$, we can define three $1271x1271$ matrices (corresponding to fixating on each of the three choice items) that represents the probability of transition from and to each of the new relative evidence states. 

In each trial, at time step 0, the process is in the bin defined by $x = 0$ and $y = 0$, with probability density 1. Knowing which item is fixated first, we can calculate the probability distribution over the relative evidence states at time step 1, by multiplying the current probability distribution with the corresponding transition matrix. As a result of this process, with each time step before the final one, the probability mass diffuses and moves, governed by the drift rate, and any probability mass outside the triangle (corresponding to evidence states where the process has finished) gets reset to 0. This way, we can calculate the exact probability that the process finishes in the correct time bin (given by the choice data). In the last time bin, we can simply sum the probabilities over the relative evidence states that correspond to the eventually chosen item. The upper panel in Figure \ref{fig:process} illustrates the movement of the probability mass over time, whereas the lower panel shows the summed probabilities after each time step. To make sure that this estimation method is completely free of stochasticity, we used a deterministic fixation pattern, based on which item was fixated first in the 200 ms bin. 

Once we were able to calculate the choice probabilities using this method, we again started off with a grid search to find the best fitting parameters for each participant and subjective value transformation rule. We used the following $3x3x3=27$ parameter grid: $\theta=\{0.33, 0.67, 1\}$, $\sigma=\{0.1, 0.55, 1\}$, \textit{d}=$\{0.1, 0.55, 1\}$ in running the Nelder-Mead optimization algorithm. We used a smaller grid, because there is no stochasticity in this method, but it is also computationally more intensive to calculate (calculating the likelihood for one participant takes 13 times longer compared to the simulation approach). For the same reason, we only ran the Nelder-Mead process once more after the grid search with a maximum iteration number of 100.  


\newcounter{savepage}
\cleardoublepage
\setcounter{savepage}{\arabic{page}}
\newgeometry{left=1cm,bottom=1cm, right = 1cm, top = 1cm}
\begin{landscape}
\pagenumbering{gobble}
\begin{figure}
\captionsetup{justification=centering}
\caption{Illustration of the diffusion process over 8 time steps with attention pattern $1, 1, 2, 2, 2, 3, 3, 3$; $\sigma = 0.3$; $\theta = 0.67$; $d = 1$, $r = 0.5, 0.5, 0.5$}
\centering
\includegraphics[width=1\textwidth]{process.pdf}
\label{fig:process}
\end{figure}
\end{landscape}
\restoregeometry
\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{\thesavepage} 
 

\subsection{Results}

The model fitting process resulted in $50x4=200$ likelihoods for each of the two methods, for each participant and value transformation rule. We wished to determine which value transformation rule produces the highest likelihood for each participant and method. Since the fitted models have the same number of parameters and are calculated on the same set of data, the likelihoods are directly comparable. Table \ref{table:chap1res} shows the result of this comparison by estimation method.
 
 
\begin{table}[ht]
\caption{Best fitting model for each participant by estimation method.}
\centering
\begin{tabular}{ccccc}   

\toprule Approach  & Global Max    & Local Max & Rank & Range \\ 
\midrule Simulations  &  29 (58\%) & 11 (22\%)  & 4 (8\%)   & 6 (12\%) \\
       Probability Distribution & 29 (58\%)  &    10 (20\%)    & 6 (12\%)   & 5  (10\%)  \\
\bottomrule 
\end{tabular}
\label{table:chap1res}
\end{table}

The two estimation approaches have yielded very similar results. For the majority of participants (58\%), the global maximum rule provided the best fit, regardless of the estimation approach. This is followed by the local maximum rule, which provided the best fit for 22-20\% of the participants. The range and rank rules proved to be the best fitting model for only about 10\% of participants. Overall, these results point to a mechanism where subjective valuation mostly depends on the absolute value of the options, and, albeit to a lesser extent, is also affected by the relative magnitude of the options (compared to the maximum value on the current trial). In addition, the almost identical results from the two estimation approaches underline the robustness of the findings, and alleviates concerns about the reliability of the simulations approach.

 
 
\section{Experiment 2}

In Experiment 2, we were still interested in testing the explanatory power of the four value transformation rules using the choice set manipulations, but we used a fundamentally different stimuli and estimation approach.

Experiment 2 had several rationales. First and foremost, comparing the results from a qualitative comparison of choice probabilities with the results from a model fitting approach allows us to gain a deeper understanding of the relative explanatory power of each value transformation rule. While we have some choice data on the seven relevant choice sets from Experiment 1, due to the error in the experimental procedure, it is not enough to conduct a test with appropriate statistical power. Second, it can be argued that the preference ratings participants gave in the first part of Experiment 1 are already context-dependent, since the movies are evaluated with respect to each other in the ratings task, which could affect our results. Finally, since the movie stimuli is somewhat complex in the sense that there are a range of factors we could not control for (e.g. visual saliency, mnemonic processes the stimuli can induce), it seems appropriate to repeat the experiment with a simpler, and more neutral stimuli. 

\subsection{Method}

We recruited 130 participants through the University of Warwick's Research Participation System. On each trial, participants were presented with a trinary set of rapidly changing sequences of numbers (first used in \citeauthor{Tsetsos2012a}) and were asked to pick the sequence with the highest average of numbers by pressing the corresponding keyboard key (left, down, right arrow). The numbers were updated every 210-250 ms. To familiarise participants with the task, the experiment began with three practice trials, where feedback were given on which sequence they chose. After the practice trials, there were 140 trials to be completed in two blocks. Participants could take a break for as long as they wished between the two blocks and they were paid £5.00 for taking part in the experiment. Figure \ref{fig:experi2_numbers} shows one trial from this experiment. The experiment on average took about 15 minutes to complete. Ethical approval was obtained from the Department of Psychology, University of Warwick.

\begin{figure}
\captionsetup{justification=centering}
\centering
\caption{Example trial from Experiment 2.}
\includegraphics[width=0.7\textwidth]{experi2.png}
\label{fig:experi2_numbers}
\end{figure}

\subsection{Stimuli}

Numbers for each presented sequence were derived from a truncated normal distribution with a standard deviation of 18, and a mean that was calculated from a monotonic transformation of the ratings from Experiment 1. Specifically, we multiplied each number by ten and then added ten to them, so a trial with values 1,2,4 in Experiment 1 corresponded to a trial with means 20, 30, 50 in Experiment 2. The distribution was truncated to only include numbers between 0 and 99. We chose to work with the two-digit equivalents of the values from Experiment 1 to increase the range of numbers that could be sampled, and the constant was added to shift the lower end of the value distributions away from 0. When a number below 10 was sampled, it was displayed as a two-digit number with 0 as the first digit. 


\subsection{Results}

For a qualitative test of the four value transformation rules, for each choice set manipulation, we compared the resulting choice proportions from both experiments with predictions from simulating out the ddm. These simulations focused only on the eventually chosen item, and did not take into account the RTs. Although the qualitative patterns of predicted choice proportions are largely insensitive to the exact parameter values, for the sake of comparability, we decided to use the same parameter pair ($\sigma$ and \textit{d}) in all simulations. This parameter pair was derived in the following way.

Using data from Experiment 1, our goal was to select the parameter pair that provided the best fit across all four value transformation rules on average. First, using a $5x5=25$ grid space with $d=\{0.01, 0.03, 0.1, 0.32, 1\}$ and $\sigma=\{0.01, 0.03, 0.1, 0.32, 1\}$,  we calculated the difference between the predicted and actual choice probabilities for each parameter pair and value transformation rule. We simulated out the DDM 100,000 times to obtain the predicted probabilities. This allowed us to rank each of the 25 parameter pairs for each value transformation rule based on how well it fits the actual data (for each rule, the parameter pair that produced the smallest difference between predicted and actual probabilities was allocated a rank of 1, while the pair that produced the highest difference receved a rank of 25). Then, using the parameter pair that had the smallest sum of ranks across the four value transformation rules, we started a Nelder-Mead optimisation process that aimed to minimise the average probability difference across all rules. We once more restarted the Nelder-Mead process using the previous parameter results, which finally produced the parameter pair $d=0.012$ and $\sigma=0.0761$.

Figures \ref{fig:addconstant_all}-\ref{fig:multiply_all} show the results from this qualitative comparison. In these figures, the four panels to the left correspond to the choice proportion predictions from the DDM simulations, while the two panels on the right show the resulting choice proportions from the two experiments and their associated 95\% CIs. All model predictions are based on 100,000 simulations. The difference in the precision of the estimates from the two experiments reflects the differences in the amount of choice data for the relevant choice sets.  

\textbf{Adding a constant.} Figure \ref{fig:addconstant_all} shows the effect of adding a constant. Unfortunately, the wide confidence intervals around the choice proportions from Experiment 1 do not allow us to see any clear patterns, but the results from Experiment 2 are broadly in line with the predictions from the local maximum rule. In summary, the results from adding a constant lend partial support to the local maximum rule.  


\begin{figure}[!htb]
\captionsetup{justification=centering}
\centering
\caption{Choice set manipulation adding a constant}
\includegraphics[width=0.9\textwidth]{exp1_addconstres.pdf}
\label{fig:addconstant_all}
\end{figure}

\textbf{Multiplying by a constant.} Figure \ref{fig:multiply_all} shows the effect of multiplying each value by a constant, where only the global maximum rule predicts a change in the choice proportions. Specifically, it predicts that the best option will benefit from adding a constant to each value. The results from both experiments are in line with these predictions, strongly supporting the global maximum rule.

\begin{figure}[!htb]
\captionsetup{justification=centering}
\centering
\caption{Choice set manipulation multiplication by constant}
\includegraphics[width=0.9\textwidth]{exp1_multiplytres.pdf}
\label{fig:multiply_all}
\end{figure}

\textbf{Distant vs close second.} Figure \ref{fig:distclose2nd_all} shows the results from the close versus distant second choice set manipulation. Only the rank rule does not predict any change in the choice proportions, and we chose this manipulation because it allows us to evaluate the explanatory power of the rank rule. Results from the two experiments show that there is a substantial change in the choice proportions, as the middle item becomes relatively more attractive compared to the best item, which was predicted by all the other value transformation rules. Therefore, the distant versus close second choice manipulation rules provides strong evidence against the rank rule. 


\begin{figure}[!htb]
\captionsetup{justification=centering}
\centering
\caption{Choice set manipulation close versus distant middle}
\includegraphics[width=0.9\textwidth]{exp1_distclosesecres.pdf}
\label{fig:distclose2nd_all}
\end{figure}

\textbf{Distant vs close third.} Finally, Figure \ref{fig:closedist3rd_all} shows the results from the close versus distant third choice set manipulation. The predictions of the value transformation rules differ significantly, the two maximum rules predicting that the worst option will benefit at the expense of the other two, the range rule predicting that the middle item will become relatively less attractive compared to the best due to the increased proximity of the worst item and the decrease in the range of values. The rank rule does not predict any change.  While the results from Experiment 2 unequivocally support the predictions of the two maximum rules, the results form Experiment 1 are more mixed (although we can detect a clear increase in the choice proportion of the  middle item). Therefore, the close versus distant third offers support for the two maximum rules.

\begin{figure}[!htb]
\captionsetup{justification=centering}
\centering
\caption{Choice set manipulation close versus distant third}
\includegraphics[width=0.9\textwidth]{exp1_distclosethirdres.pdf}
\label{fig:closedist3rd_all}
\end{figure}


To summarize, the results from the qualitative comparisons suggest that the two maximum normalisation rules had the highest explanatory power. More specifically, albeit to varying degrees, but both rules predicted the effect of three out of the four choice set manipulations, the range rule successfully predicted one, and the rank rule did not predict the effect of any of the choice set manipulations.

This can be contrasted with the results from the model fitting approach, which indicated that the global maximum rule has the highest explanatory power by far. In line with this, multiplication by a constant, which was only correctly predicted by the global maximum rule, resulted in the largest difference between choice proportions in Experiment 1.


In addition, interestingly, even though the two experiments involved fundamentally different stimuli (complex versus perceptual), the effects of the choice set manipulations on the choice proportions turned out to be rather similar. Unfortunately, a strict comparison of the two datasets is hindered by the relatively small sample size of Experiment 1. Nevertheless, the results lend some support to the idea that there exists a common valuation mechanism across a range of stimuli domains.



\newpage

\section{Discussion}

In this research project, our aim was to conduct a comprehensive evaluation of the relative explanatory power of four different forms of context-dependency. To compare four value transformation rules, each of which captures a different form of context-dependent valuation, we used a popular cognitive model, the DDM and its extension, the aDDM, to derive predictions about choice behaviour in two choice experiments with trinary choice sets, one with complex stimuli (movie posters), and another one with a perceptual task.

Two fundamentally different approaches, a quantitative approach that entailed fitting the aDDM to choice and eye-tracking data from Experiment 1, and a qualitative approach, involving the inspection of resulting choice proportions from both experiments were used for the comparison. The results from the two comparison methods were broadly in line, both supporting the view that while subjective valuation mostly reflects the absolute magnitude of the options under consideration, to a lesser extent, it is also affected by the relative value of the options (within the local context).

These findings are consistent with insights from research investigating the neural correlates of value-based decision making. Results from numerous neuroeconomic studies strongly support the view that the orbifrontal cortex (OFC) is the brain region where subjective value encoding takes place in economic choices (for a review see \citeNP{Padoa-Schioppa2017}). More importantly, it has been suggested that there is a group of neurons in the OFC with two fundamental properties that are likely to be directly responsible for simultaneous absolute and relative value sensitivity in economic valuation.

First, \citeA{Padoa-Schioppa2008} have shown that such neurons exhibit menu invariance, meaning that the value assigned to each option under consideration is independent from the value of the rest of the available alternatives, reflecting the absolute value of the option (global maximum in our experiments). Menu invariance gives rise to preference transitivity, ensuring that preferences are stable across the wide range of contexts the decision maker might encounter. Second, there is ample evidence that neuronal firing rates adapt to the range of available values (e.g., \citeNP{Padoa-Schioppa2009}; \citeNP{Louie2013}). Such adaptation is widespread in sensory systems, and is a natural consequence of biophysical constraints. Interestingly, although the most commonly proposed form of adaptation in the neuroeconomic literature is range adaptation (e.g., \citeNP{Soltani2012}), our data suggests that normalising by the maximum on the current trials fares better than a range normalisation approach at predicting choice.


There exist other ways to model context-sensitivity within the sequential sampling framework. Another approach to investigate context-dependency could have been to directly model changes in the drift rate. This could be done within an experiment where the range of values encountered are manipulated block by block (e.g., as done in \citeNP{Mullett2013}), and the model fitting approach can evaluate the explanatory power of various forms of context-dependency.

In addition, we could have investigated mixtures of models, for example, a hybrid model, where the subjective value is partly affected by the absolute value and partly affected by the local maximum transformation. Such investigations would have required estimation an additional, mixing parameter, which determines the degree to which each rule affects the subjective value.


 Alternatively, instead of changing the input values of the accumulation equation, we could have focused on how these values are integrated and incorporated into the accumulation process (described in Equations \ref{REA1}-\ref{REA3}). This is what \citeA{Teodorescu2016} did in a somewhat similar investigation to ours. Specifically, they contrasted relative and absolute evidence processing in a sequential sampling framework by comparing an independent race model (capturing absolute value processing, where the input is the absolute value of the options), with a DDM model (where differences of input values govern the accumulation process).

In their experiment, participants were instructed to choose the brighter out of two, fluctuating grey patches, with a fixed mean brightness. They focused on two manipulations: in an additive-boost condition, they added the same constant to both means, preserving the difference between the two mean brightness, whereas in the multiplicative-boost condition, they multiplied both means by the same constant, preserving the ratio of the two means. These conditions are direct equivalents to our add a constant, and multiply by a constant choice set manipulations.

Interestingly, they found that no "pure" (either entirely absolute or relative) accumulation model could account for the data, and thus they propose two distinct types  of models that can account for this pattern: a DDM model where the noise in the process is a function of the intensity of the inputs, and a leaky competing accumulator model (LCA; \citeNP{Usher2001}), where simultaneous absolute and relative value sensitivity is a result of lateral inhibition. 

While our approach is different from that of \citeA{Teodorescu2016}, our results are similar, as they both suggest that subjective valuation are sensitive to both the absolute and relative magnitudes of objective values. This dovetails with findings from neuroeconomic research that suggests that OFC neurons exhibit both menu invariance and range adaptation. Taken together, these results point to a sequential sampling model with some form of hybrid value transformation rule. Since an ever increasing amount of research focuses on understanding the neural basis of economic decision making, insights from this field will no doubt inform and greatly advance the explanatory power of cognitive models of choice in the future.

\bibliographystyle{apacite}

\newpage

\bibliography{refs}

\end{document}